{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66032301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.mlspace/envs/FedCDR/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib as Path\n",
    "import random\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pickle as pkl\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from src_dataloadre import Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a1b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from legacy_dataloeders import TrainDataset, collate_fn, EvalDatasetGTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e826824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['mega', 'zvuk']\n",
    "max_seq_len = 200\n",
    "\n",
    "data_path = Path.Path('/home/jovyan/Samra/fl-recsys-adaptation/data/mega_zvuk-overlap50-minuser10-positives/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81841550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_domain_data(data_path: Path):\n",
    "\n",
    "    train_df = (\n",
    "        pl.scan_parquet(data_path / 'train.parquet')\n",
    "        .group_by('uid')\n",
    "        .agg(pl.col('item_id'), pl.col('timestamp'))\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    val_df = (\n",
    "        pl.scan_parquet(data_path / 'val.parquet')\n",
    "        .group_by('uid')\n",
    "        .agg(pl.col('item_id'), pl.col('timestamp'))\n",
    "        .collect()\n",
    "    )\n",
    "    test_df = (\n",
    "        pl.scan_parquet(data_path / 'test.parquet')\n",
    "        .group_by('uid')\n",
    "        .agg(pl.col('item_id'), pl.col('timestamp'))\n",
    "        .collect()\n",
    "    ).with_columns(pl.col('uid').cast(pl.Int32))\n",
    "    train_val_df = (pl.concat([\n",
    "        pl.scan_parquet(data_path / 'train.parquet'),\n",
    "        pl.scan_parquet(data_path / 'val.parquet'),\n",
    "        ])\n",
    "        .group_by('uid')\n",
    "        .agg(pl.col('item_id'), pl.col('timestamp'))\n",
    "        .collect()\n",
    "    ).with_columns(pl.col('uid').cast(pl.Int32))\n",
    "\n",
    "    with open(data_path / 'item_id_to_idx.pkl', 'rb') as f:\n",
    "        item_id_to_idx = pkl.load(f)\n",
    "\n",
    "    num_items = len(item_id_to_idx)\n",
    "\n",
    "    return train_df, val_df, train_val_df, test_df, num_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b4f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs, val_dfs, train_val_dfs, test_dfs, num_items = [], [], [], [], []\n",
    "for domain in domains: \n",
    "    train_df, val_df, train_val_df, test_df, num_item = read_domain_data(data_path / domain)\n",
    "    train_dfs.append(train_df)\n",
    "    test_dfs.append(test_df)\n",
    "    train_val_dfs.append(train_val_df)\n",
    "    val_dfs.append(val_df)\n",
    "    num_items.append(num_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad136c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143928\n"
     ]
    }
   ],
   "source": [
    "all_users = np.union1d(train_dfs[0]['uid'].unique().to_numpy(), train_dfs[1]['uid'].unique().to_numpy())\n",
    "print(len(all_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87267d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_2_index = dict(zip(all_users, np.arange(len(all_users))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = [df.with_columns(pl.col('uid').replace_strict(uid_2_index)) for df in train_dfs]\n",
    "test_dfs = [df.with_columns(pl.col('uid').replace_strict(uid_2_index)) for df in test_dfs]\n",
    "val_dfs = [df.with_columns(pl.col('uid').replace_strict(uid_2_index)) for df in val_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "008e36b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/95952 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95952/95952 [04:15<00:00, 375.21it/s]\n",
      "100%|██████████| 95952/95952 [04:15<00:00, 376.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, domain in enumerate(domains):\n",
    "    os.makedirs(f'data/{domain}', exist_ok=True)\n",
    "\n",
    "    train_dataset = TrainDataset(dataset=train_dfs[i], num_items=num_items[i],\n",
    "                                    max_seq_len=max_seq_len, num_neg_items=1)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=1,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        prefetch_factor=4,\n",
    "    )\n",
    "    with open(f\"data/{domain}/train_data.txt\", \"w\") as f:\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            user_id = int(batch[\"user.ids\"][0])\n",
    "            items = batch[\"item.ids\"].tolist()\n",
    "\n",
    "            f.write(str(user_id))\n",
    "            for item in items:\n",
    "                f.write(f\"\\t{item}\")\n",
    "            f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d01ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_dataloader(train_df, eval_df, max_seq_len, batch_size, seed=42, eval_mode='random'):\n",
    "    \n",
    "    eval_df = train_df.join(eval_df, on='uid', how='inner', suffix='_valid').select(\n",
    "        pl.col('uid'), pl.col('item_id').alias('item_id_train'), pl.col('item_id_valid')\n",
    "    ).sort('uid')\n",
    "    eval_dataset = EvalDatasetGTS(dataset=eval_df, max_seq_len=max_seq_len, seed=seed, mode=eval_mode)\n",
    "\n",
    "    eval_dataloader = DataLoader(\n",
    "        dataset=eval_dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=False,\n",
    "        num_workers=8,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return eval_df, eval_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b01af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 387/28600 [00:01<01:20, 350.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28600/28600 [01:18<00:00, 365.16it/s]\n",
      "100%|██████████| 44587/44587 [02:03<00:00, 360.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, domain in enumerate(domains):\n",
    "    os.makedirs(f'data/{domain}', exist_ok=True)\n",
    "\n",
    "    eval_df, eval_dataloader = get_eval_dataloader(train_dfs[i], val_dfs[i], max_seq_len, 1, eval_mode='last')\n",
    "    with open(f\"data/{domain}/valid_data.txt\", \"w\") as f:\n",
    "        for batch in tqdm(eval_dataloader):\n",
    "            user_id = int(batch[\"user.ids\"][0])\n",
    "            items = batch[\"item.ids\"].tolist()\n",
    "\n",
    "            f.write(str(user_id))\n",
    "            for item in items:\n",
    "                f.write(f\"\\t{item}\")\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee499ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24799 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24799/24799 [01:08<00:00, 360.24it/s]\n",
      "100%|██████████| 24799/24799 [01:07<00:00, 368.57it/s]\n",
      "100%|██████████| 24799/24799 [01:07<00:00, 369.28it/s]\n",
      "100%|██████████| 42625/42625 [01:58<00:00, 359.53it/s]\n",
      "100%|██████████| 42625/42625 [01:57<00:00, 362.92it/s]\n",
      "100%|██████████| 42625/42625 [01:59<00:00, 357.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, domain in enumerate(domains):\n",
    "    os.makedirs(f'data/{domain}', exist_ok=True)\n",
    "    with open(f\"data/{domain}/test_data.txt\", \"w\") as f:\n",
    "        for seed in [42, 41, 43]:\n",
    "            eval_df, eval_dataloader = get_eval_dataloader(train_val_dfs[i], test_dfs[i], max_seq_len, batch_size=1, eval_mode='random', seed=seed)\n",
    "            for batch in tqdm(eval_dataloader):\n",
    "                user_id = int(batch[\"user.ids\"][0])\n",
    "                items = batch[\"item.ids\"].tolist()\n",
    "\n",
    "                f.write(str(user_id))\n",
    "                for item in items:\n",
    "                    f.write(f\"\\t{item}\")\n",
    "                f.write(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef967b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, domain in enumerate(domains):\n",
    "    os.makedirs(f'data/{domain}', exist_ok=True)\n",
    "    with open(f\"data/{domain}/num_items.txt\", \"w\") as f:\n",
    "        f.write(f'{num_items[i]}')\n",
    "    with open(f\"data/{domain}/item_users.txt\", \"w\") as f:\n",
    "        f.write(f'{len(train_dfs[i])}')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cddcaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedCDR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
